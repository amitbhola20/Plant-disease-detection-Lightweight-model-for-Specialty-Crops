{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vahcYJ4go-sK"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D, GlobalMaxPooling2D, Dense, Input, Concatenate\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set variables and hyperparameters\n",
        "\n",
        "input_shape = (224, 224, 3)\n",
        "num_classes = 16\n",
        "output_activation = 'softmax'\n",
        "activation_function = 'relu'\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "batch_size = 32\n",
        "epochs = 50\n",
        "loss_function = 'categorical_crossentropy'\n",
        "\n",
        "train_dir = '/content/drive/MyDrive/Research/Data/Dataset/train'\n",
        "val_dir = '/content/drive/MyDrive/Research/Data/Dataset/validate'\n",
        "test_dir = '/content/drive/MyDrive/Research/Data/Dataset/test'"
      ],
      "metadata": {
        "id": "pel-5HlhpE1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the dataset\n",
        "def preprocess_data(train_dir, val_dir, test_dir, input_size=(224, 224), batch_size=batch_size):\n",
        "    datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, width_shift_range=0.2,\n",
        "                                 height_shift_range=0.2, horizontal_flip=True)\n",
        "\n",
        "    train_generator = datagen.flow_from_directory(train_dir, target_size=input_size, batch_size=batch_size, class_mode='categorical')\n",
        "    val_generator = datagen.flow_from_directory(val_dir, target_size=input_size, batch_size=batch_size, class_mode='categorical')\n",
        "    test_generator = datagen.flow_from_directory(test_dir, target_size=input_size, batch_size=batch_size, class_mode='categorical')\n",
        "\n",
        "    return train_generator, val_generator, test_generator"
      ],
      "metadata": {
        "id": "0NU2AapMpEzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture\n",
        "def create_model(input_shape, num_classes):\n",
        "    # Input layer\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # First convolutional level\n",
        "    conv1 = Conv2D(32, (3, 3), activation=activation_function)(inputs)\n",
        "    gmpl1 = GlobalMaxPooling2D()(conv1)\n",
        "    fc1 = Dense(64, activation=activation_function)(gmpl1)\n",
        "\n",
        "    # Second convolutional level\n",
        "    conv2 = Conv2D(64, (3, 3), activation=activation_function)(inputs)\n",
        "    gmp2 = GlobalMaxPooling2D()(conv2)\n",
        "    fc2 = Dense(64, activation=activation_function)(gmp2)\n",
        "\n",
        "    # Third convolutional level\n",
        "    conv3 = Conv2D(128, (3, 3), activation=activation_function)(inputs)\n",
        "    gmp3 = GlobalMaxPooling2D()(conv3)\n",
        "    fc3 = Dense(64, activation=activation_function)(gmp3)\n",
        "\n",
        "    # Concatenate layers\n",
        "    # First Concatenation\n",
        "    concatenate1 = Concatenate()([fc1, fc2])\n",
        "\n",
        "    # Second Concatenation\n",
        "    concatenate2 = Concatenate()([concatenate1, fc3])\n",
        "\n",
        "    # Fully Connected Layers after Concatenation\n",
        "    fc4 = Dense(128, activation=activation_function)(concatenate2)\n",
        "    fc5 = Dense(64, activation=activation_function)(fc4)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = Dense(num_classes, activation=output_activation)(fc5)\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "IlDinqospEw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "def compile_model(model):\n",
        "    model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "NAOS2w1apEu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "def train_model(model, train_generator, val_generator, epochs=epochs):\n",
        "    history = model.fit(train_generator, validation_data=val_generator, epochs=epochs)\n",
        "    return history"
      ],
      "metadata": {
        "id": "-FyYQx_JpEsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "def evaluate_model(model, test_generator):\n",
        "    results = model.evaluate(test_generator)\n",
        "    return results"
      ],
      "metadata": {
        "id": "Sh6bzqJApEpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute and Test the model\n",
        "\n",
        "train_generator, val_generator, test_generator = preprocess_data(train_dir, val_dir, test_dir)\n",
        "model = create_model(input_shape, num_classes)\n",
        "compile_model(model)\n",
        "history = train_model(model, train_generator, val_generator)\n",
        "test_results = evaluate_model(model, test_generator)"
      ],
      "metadata": {
        "id": "TmaNfRQLpEnI",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}